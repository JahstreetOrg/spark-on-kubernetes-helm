livy:

  image:
    pullPolicy: Always

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/tls-acme: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$1
      # nginx.ingress.kubernetes.io/auth-type: basic
      # nginx.ingress.kubernetes.io/auth-secret: kube-system/auth-secret
      # nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
    path: /livy/?(.*)
    hosts:
    - my-cluster.example.com
    tls:
    - secretName: spark-cluster-tls
      hosts:
      - my-cluster.example.com

  persistence:
    enabled: true

  env:
    LIVY_LIVY_UI_BASE1PATH: {value: "/livy"}
    LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1POLICY: {value: "Always"}
    # Configure Ingresses for Spark UIs
    LIVY_LIVY_SERVER_KUBERNETES_INGRESS_CREATE: {value: "true"}
    LIVY_LIVY_SERVER_KUBERNETES_INGRESS_PROTOCOL: {value: "https"}
    LIVY_LIVY_SERVER_KUBERNETES_INGRESS_HOST: {value: "my-cluster.example.com"}
    LIVY_LIVY_SERVER_KUBERNETES_INGRESS_TLS_SECRET1NAME: {value: "spark-cluster-tls"}
    # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-url=https://$host/oauth2/auth;nginx.ingress.kubernetes.io/auth-signin=https://$host/oauth2/start?rd=$escaped_request_uri"}
    # Configure History Server
    LIVY_SPARK_EVENT1LOG_ENABLED: {value: "false"}
    LIVY_SPARK_EVENT1LOG_DIR: {value: "file:///tmp/history-server"}
    LIVY_LIVY_UI_HISTORY0SERVER0URL: {value: "https://my-cluster.example.com/history-server"}
    # Configure Grafana Loki integration
    # LIVY_LIVY_SERVER_KUBERNETES_GRAFANA_LOKI_ENABLED: {value: "true"}
    # LIVY_LIVY_SERVER_KUBERNETES_GRAFANA_URL: {value: "https://my-cluster.example.com/grafana"}
    # Configure default nodepool for Spark Pods
    LIVY_SPARK_KUBERNETES_NODE_SELECTOR_AGENTPOOL: {value: "sparkpool"}

  sparkDefaultsConf: {}
    # fromSecret: "livy-client-conf-secret"
  
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: autoscale-retain
            operator: In
            values:
            - "true"

historyserver:
  enabled: false

  image:
    pullPolicy: Always

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/tls-acme: "true"
      nginx.ingress.kubernetes.io/rewrite-target: /$1
      nginx.ingress.kubernetes.io/proxy-redirect-from: http://$host/history/
      nginx.ingress.kubernetes.io/proxy-redirect-to: /history-server/history/
      nginx.ingress.kubernetes.io/configuration-snippet: |
        proxy_set_header Accept-Encoding ""; # disable compression
        sub_filter_last_modified off;
        # Adding a `base href` and stripping the leading `/` from href/src tightly covers most all URL
        sub_filter '<head>' '<head> <base href="/history-server/">'; # add base url
        sub_filter 'href="/' 'href="'; # remove absolute URL path so base url applies
        sub_filter 'src="/' 'src="'; # remove absolute URL path so base url applies

        sub_filter '/{{num}}/jobs/' '/jobs/';

        sub_filter "setUIRoot('')" "setUIRoot('/history-server')"; # Set UI root for JS scripts
        sub_filter "document.baseURI.split" "document.documentURI.split"; # Executors page issue fix

        sub_filter_once off;
        sub_filter_types text/html text/css text/javascript application/javascript; # Specify filter types to prevent processing all files
      # nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      # nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    path: /history-server/?(.*)
    hosts:
    - my-cluster.example.com
    tls:
    - secretName: spark-cluster-tls
      hosts:
      - my-cluster.example.com
  pvc:
    enablePVC: false
  nfs:
    enableExampleNFS: false
  wasbs:
    enableWASBS: true
    sasKeyMode: true
    secret: spark-history-server-secret
    logDirectory: wasbs:///history-server

jupyterhub:
  enabled: true

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/tls-acme: "true"
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
      # nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      # nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    hosts:
    - my-cluster.example.com
    pathSuffix: ''
    tls:
    - secretName: spark-cluster-tls
      hosts:
      - my-cluster.example.com

  hub:

    # Set up in addition to ingress
    baseUrl: /jupyterhub
    publicURL: "https://my-cluster.example.com"
    activeServerLimit: 10

    # For Azure AD OAuthenticator (https://github.com/jupyterhub/oauthenticator/issues/218)
    extraEnv:
      AAD_TENANT_ID: "<TENANT_ID>"

    # $> openssl rand -hex 32
    cookieSecret: 41b85e5f50222b1542cc3b38a51f4d744864acca5e94eeb78c6e8c19d89eb433
    nodeSelector:
      autoscale-retain: "true"
    pdb:
      enabled: true
      minAvailable: 0

  auth:
    # Azure AD OAuthenticator
    type: custom
    custom:
      className: oauthenticator.azuread.AzureAdOAuthenticator
      config:
        oauth_callback_url: "https://my-cluster.example.com/jupyterhub/hub/oauth_callback"
        client_id: "<WEB_APP_CLIENT_ID>"
        client_secret: "<WEB_APP_CLIENT_SECRET>"
        # https://github.com/jupyterhub/oauthenticator/issues/218
        tenant_id: "<TENANT_ID>"
    whitelist:
      users:
    admin:
      access: true
      users:
      - user name

  proxy:
    # $> openssl rand -hex 32
    secretToken: cc52356e9a19a50861b22e08c92c40b8ebe617192f77edb355b9bf4b74b055de
    nodeSelector:
      autoscale-retain: "true"
    pdb:
      enabled: true
      minAvailable: 0

  singleuser:
    nodeSelector:
      agentpool: sparkpool
    extraNodeAffinity:
      preferred:
      - weight: 10
        preference:
          matchExpressions:
          - key: autoscale-retain
            operator: NotIn
            values:
            - "true"